{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare samples with SampComp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In brief"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T20:11:22.488847Z",
     "start_time": "2019-03-29T20:11:22.481742Z"
    }
   },
   "source": [
    "First, `SampComp` parses the sample eventalign collapse files and then the observed results are piled-up per reference at position level. In a second time, positions are compared using various statistical methods and the statistics are stored in a shelve DBM database containing the results for all positions with sufficient coverage. The API returns a `SampCompDB` database wrapper object that can be subsequently interrogated to extract data and plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example CLI call\n",
    "\n",
    "```bash\n",
    "nanocompore sampcomp \\\n",
    "    --file_list1 ./data/S1_R1.tsv,./data/S1_R2.tsv \\\n",
    "    --file_list2 ./data/S2_R1.tsv,./data/S2_R2.tsv \\\n",
    "    --label1 S1 \\\n",
    "    --label2 S2 \\\n",
    "    --fasta ./reference/ref.fa \\\n",
    "    --outpath ./results/ \\\n",
    "```\n",
    "\n",
    "Example API call\n",
    "\n",
    "```python\n",
    "# Import package\n",
    "from nanocompore.SampComp import SampComp\n",
    "\n",
    "# Init the object\n",
    "s = SampComp(\n",
    "    eventalign_fn_dict = {\n",
    "        'S1':{'rep1':'./data/S1_R1.tsv', 'rep2':'./data/S1_R2.tsv'},\n",
    "        'S2':{'rep1':'./data/S2_R1.tsv', 'rep2':'./data/S2_R2.tsv'}},\n",
    "    outpath = \"./results/\",\n",
    "    fasta_fn = \"./reference/ref.fa\")\n",
    "\n",
    "# Run the analysis\n",
    "s()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of main options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SampComp` provides a very flexible analysis framework with a few mandatory options and many optional parameters. The full CLI and API documentations are provided at the bottom of this page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Sample files\n",
    "\n",
    "`SampComp` requires sample files obtained with `NanopolishComp EventalignCollapse` as explained before (see [data preparation](data_preparation.md)) for both the control and the experimental conditions. 2 conditions are expected and at least 2 replicates per conditions are highly recommended. If `SampComp` is called through the CLI the files can be provided using either relevant command options or a YAML file. With the Python API you can pass either a python dictionary or a YAML file.\n",
    "\n",
    "!!! info \"YAML file option (CLI or API)\"\n",
    "    This option allows to pass a YAML formatted file indicating the sample condition labels and paths to data files with the option `--sample_yaml` for the CLI or directly with `eventalign_fn_dict` for the API. The file should be formatted as follow:\n",
    "\n",
    "    ```yaml\n",
    "    WT:\n",
    "        rep1:   ./data/S1_R1.tsv\n",
    "        rep2:   ./data/S1_R2.tsv\n",
    "\n",
    "    KO:\n",
    "        rep1:   ./data/S2_R1.tsv\n",
    "        rep2:   ./data/S1_R2.tsv\n",
    "    ```\n",
    "\n",
    "!!! info \"Command line option (CLI only)\"\n",
    "\tThis option requires to provide a comma separated list of files per condition using `--file_list1` and `--file_list2` arguments as well as the labels for condition each conditions using `--label1` and `--label2`.\n",
    "\n",
    "!!! info \"Python dictionary (API only)\"\n",
    "    This option allows to pass a multi-level python dictionary containing the sample condition labels and paths to data files. The dictionary should be formatted as follow:\n",
    "\n",
    "    ```python\n",
    "    eventalign_fn_dict = {\n",
    "        \"WT\":  {\"rep1\":\"./data/S1_R1.tsv\", \"rep2\":\"./data/S1_R2.tsv\"},\n",
    "        \"KO\": {\"rep1\":\"./data/S2_R1.tsv\", \"rep2\":\"./data/S1_R2.tsv\"}\n",
    "        }\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transcriptome reference FASTA file\n",
    "\n",
    "A transcriptome FASTA reference file is required to extract kmer sequences during the analyses. The reference has to be the same as the one used at the mapping step. (CLI: `--fasta`, API: `fasta_fn`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output folder\n",
    "\n",
    "Although it is not mandatory, it is recommended to provide a path to a directory where the program will output the result files  (CLI: `--outpath`, API: `outpath`). In addition, users can also specify a prefix for the files to be generated (CLI: `--outprefix`, API: `outprefix`). Finally, if the outpath directory already exists, the program will raise an error to avoid erasing result files. To ignore the error you can to specify to overwrite previous results (CLI: `--overwrite`, API: `overwrite`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Genome annotation BED file\n",
    "\n",
    "Optionally, a BED file containing the genome annotations corresponding to the transcriptome fasta file can be provided. In that case Nanocompore will also convert the transcript coordinates into the genome space (CLI: `--bed`, API: `bed_fn`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistical options\n",
    "\n",
    "`SampComp` implements several statistical methods to evaluate the difference between the 2 conditions (`comparison_method`).\n",
    "\n",
    "* Gaussian Mixture Model = GMM (default)\n",
    "* Kolmogorov–Smirnov test = KS (default)\n",
    "* Mann–Whitney U test = MW\n",
    "* T-test = TT\n",
    "\n",
    "In addition, it is also possible to specify the number of adjacent positions to take into account for the pvalue calculation (`sequence_context`) as well as the weights to give to adjacent position, using either an \"uniform\" or a \"harmonic\" distribution (`sequence_context_weights`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coverage options\n",
    "\n",
    "The default coverage threshold for `SampComp` to perform a statistical test is 30 reads in each replicates. This is quite conservative and can be modified if needed (`min_coverage`). In addition, to reduce the computational burden it is possible to randomly down-sample the number of reads for high coverage references (`downsample_high_coverage`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manually exclude or include references (API only)\n",
    "\n",
    "The API allows to specify references to be included or excluded from the analysis (`select_ref_id` and\n",
    "`exclude_ref_id`). This can be useful to analyse a specific set of transcripts or to run a small test before analysing the whole dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced API Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T13:11:11.501727Z",
     "start_time": "2019-06-19T13:11:11.499264Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "from nanocompore.SampComp import SampComp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a Python dictionary to specify the locations of the eventalign files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default option using a multilevel dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T13:11:37.250127Z",
     "start_time": "2019-06-19T13:11:11.503717Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialising SampComp and checking options\n",
      "Initialising Whitelist and checking options\n",
      "Reading eventalign index files\n",
      "\tReferences found in index: 125\n",
      "Filtering out references with low coverage\n",
      "\tReferences remaining after reference coverage filtering: 1\n",
      "Starting data processing\n",
      "100%|██████████| 1/1 [00:25<00:00, 25.07s/ Processed References]\n",
      "Loading SampCompDB\n",
      "Calculate results\n"
     ]
    }
   ],
   "source": [
    "# Init the object\n",
    "s = SampComp ( \n",
    "    eventalign_fn_dict = {\n",
    "        \"KO\":{\n",
    "            \"rep1\":'./eventalign_files/yeast/KO_1_eventalign_collapsed.tsv', \n",
    "            \"rep2\":\"./eventalign_files/yeast/KO_2_eventalign_collapsed.tsv\"},\n",
    "        \"WT\":{\n",
    "            \"rep1\":'./eventalign_files/yeast/WT_1_eventalign_collapsed.tsv', \n",
    "            \"rep2\":\"./eventalign_files/yeast/WT_2_eventalign_collapsed.tsv\"}},\n",
    "    outpath = \"./results\",\n",
    "    outprefix= \"yeast_\",\n",
    "    fasta_fn = \"./references/yeast/Yeast_transcriptome.fa\",\n",
    "    overwrite = True)\n",
    "\n",
    "# Run the analysis\n",
    "db = s()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a YAML file instead to specify the files location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use a YAML file, just pass a path to the file instead of a dictionary. In this example we also specify to use 10 threads to speed-up the data processing (`nthreads = 10`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T13:11:37.257827Z",
     "start_time": "2019-06-19T13:11:37.252399Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified:\n",
      "    rep1:   ./eventalign_files/simulated/modified_rep_1.tsv\n",
      "    rep2:   ./eventalign_files/simulated/modified_rep_2.tsv\n",
      "Unmodified:\n",
      "    rep1:   ./eventalign_files/simulated/unmodified_rep_1.tsv\n",
      "    rep2:   ./eventalign_files/simulated/unmodified_rep_2.tsv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read YAML file to display structure\n",
    "print(open(\"./samples.yaml\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T13:11:42.928581Z",
     "start_time": "2019-06-19T13:11:37.261542Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialising SampComp and checking options\n",
      "Initialising Whitelist and checking options\n",
      "Reading eventalign index files\n",
      "\tReferences found in index: 5\n",
      "Filtering out references with low coverage\n",
      "\tReferences remaining after reference coverage filtering: 5\n",
      "Starting data processing\n",
      "100%|██████████| 5/5 [00:05<00:00,  2.41s/ Processed References]\n",
      "Loading SampCompDB\n",
      "Calculate results\n"
     ]
    }
   ],
   "source": [
    "# Init the object\n",
    "s = SampComp (\n",
    "    eventalign_fn_dict = \"./samples.yaml\",\n",
    "    outpath= \"./results\",\n",
    "    outprefix= \"simulated_\",\n",
    "    fasta_fn = \"./references/simulated/ref.fa\",\n",
    "    overwrite = True,\n",
    "    nthreads = 10)\n",
    "\n",
    "# Run the analysis\n",
    "db = s ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweaking the statistical tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we require all 4 possible statistical tests to be performed (`comparison_methods=[\"GMM\", \"MW\", \"KS\", \"TT\"]`), and we want a pvalue that takes into account 2 adjacent positions(`sequence_context=2`). In addition we also specify that the weights for adjacent position should follow a harmonic distribution (`sequence_context_weights=\"harmonic\"`). Finally, we also want the Gaussian mixture model to use the logistic regression test on top of the ANOVA (`logit = True`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T13:12:00.581344Z",
     "start_time": "2019-06-19T13:11:42.930413Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialising SampComp and checking options\n",
      "Initialising Whitelist and checking options\n",
      "Reading eventalign index files\n",
      "\tReferences found in index: 5\n",
      "Filtering out references with low coverage\n",
      "\tReferences remaining after reference coverage filtering: 5\n",
      "Starting data processing\n",
      "100%|██████████| 5/5 [00:17<00:00,  3.45s/ Processed References]\n",
      "Loading SampCompDB\n",
      "Calculate results\n"
     ]
    }
   ],
   "source": [
    "# Init the object\n",
    "s = SampComp (\n",
    "    eventalign_fn_dict = \"./samples.yaml\",\n",
    "    outpath = \"./results/\",\n",
    "    outprefix= \"simulated_stats_\",\n",
    "    fasta_fn = \"./references/simulated/ref.fa\",\n",
    "    overwrite=True,\n",
    "    comparison_methods=[\"GMM\", \"MW\", \"KS\", \"TT\"],\n",
    "    sequence_context=2,\n",
    "    sequence_context_weights=\"harmonic\",\n",
    "    logit = True)\n",
    "\n",
    "# Run the analysis\n",
    "db = s ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the database object returned by Sampcomp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The database object returned by `Sampcomp` is a Python GDBM object database indexed by reference id. Although we highly recommend to used `SampCompDB` to extract information, it is also possible to open the database directly using the python standard library module [shelve](https://docs.python.org/3.6/library/shelve.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T13:12:00.633666Z",
     "start_time": "2019-06-19T13:12:00.583138Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'package_name': 'nanocompore', 'package_version': '1.0.0rc3-dev', 'timestamp': '2019-06-19 14:11:42.582069', 'comparison_methods': ['GMM', 'KS'], 'pvalue_tests': ['GMM_anova_pvalue', 'KS_dwell_pvalue', 'KS_intensity_pvalue'], 'sequence_context': 0, 'min_coverage': 30, 'n_samples': 4}\n",
      "['ref_0002', 'ref_0000', 'ref_0003', 'ref_0001', 'ref_0004']\n",
      "{'GMM_model': {'model': GaussianMixture(covariance_type='full', init_params='kmeans', max_iter=100,\n",
      "                means_init=None, n_components=2, n_init=1, precisions_init=None,\n",
      "                random_state=<mtrand.RandomState object at 0x7ff59c481ee8>,\n",
      "                reg_covar=1e-06, tol=0.001, verbose=0, verbose_interval=10,\n",
      "                warm_start=False, weights_init=None), 'cluster_counts': 'Modified_rep1:6/49__Modified_rep2:6/54__Unmodified_rep1:50/5__Unmodified_rep2:52/8'}, 'GMM_anova_pvalue': 0.0022723661815992765, 'GMM_anova_model': {'pvalue': 0.0022723661815992765, 'delta_logit': -3.9703346955, 'table': F_onewayResult(statistic=438.5704870887501, pvalue=0.0022723661815992765), 'log_ratios': array([-1.96611286, -2.06142304,  2.14006616,  1.77306734])}, 'KS_intensity_pvalue': 2.2306904419226962e-17, 'KS_dwell_pvalue': 1.0667209507829918e-31, 'shift_stats': OrderedDict([('c1_mean_intensity', 99.54709799468591), ('c2_mean_intensity', 91.84415815799566), ('c1_median_intensity', 100.61305720731731), ('c2_median_intensity', 92.05605629218894), ('c1_sd_intensity', 6.85551651760893), ('c2_sd_intensity', 5.143626863495356), ('c1_mean_dwell', 0.02567361308475615), ('c2_mean_dwell', 0.009745078440682191), ('c1_median_dwell', 0.023047132241771167), ('c2_median_dwell', 0.007591605413309661), ('c1_sd_dwell', 0.010681688969392145), ('c2_sd_dwell', 0.007203231747770627)])}\n"
     ]
    }
   ],
   "source": [
    "import shelve\n",
    "\n",
    "with shelve.open (\"./results/simulated_SampComp.db\") as db:\n",
    "    # Read metadata stored in metadata slot\n",
    "    print(db[\"__metadata\"])\n",
    "    # Read list of references ids stored in ref_id_list slot\n",
    "    print(db[\"__ref_id_list\"])\n",
    "    # Access stats for reference 'ref_0000' in position 1\n",
    "    print(db[\"ref_0000\"][1][\"txComp\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full CLI and API documentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T11:55:18.257622Z",
     "start_time": "2019-04-03T11:55:18.232546Z"
    }
   },
   "source": [
    "### API documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API help can be obtained with conventional python methods (help or ?) or rendered nicely in Jupyter with the jhelp function from nanocompore "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T13:12:00.648099Z",
     "start_time": "2019-06-19T13:12:00.636552Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**SampComp** (eventalign_fn_dict, fasta_fn, bed_fn, outpath, outprefix, overwrite, whitelist, comparison_methods, logit, allow_warnings, sequence_context, sequence_context_weights, min_coverage, min_ref_length, downsample_high_coverage, max_invalid_kmers_freq, select_ref_id, exclude_ref_id, nthreads, log_level)\n",
       "\n",
       "Init analysis and check args\n",
       "\n",
       "---\n",
       "\n",
       "* **eventalign_fn_dict** (required) [dict]\n",
       "\n",
       "Multilevel dictionnary indicating the condition_label, sample_label and file name of the eventalign_collapse output. 2 conditions are expected and at least 2 sample replicates per condition are highly recommended. One can also pass YAML file describing the samples instead. Example `d = {\"S1\": {\"R1\":\"path1.tsv\", \"R2\":\"path2.tsv\"}, \"S2\": {\"R1\":\"path3.tsv\", \"R2\":\"path4.tsv\"}}`\n",
       "\n",
       "* **fasta_fn** (required) [str]\n",
       "\n",
       "Path to a fasta file corresponding to the reference used for read alignment.\n",
       "\n",
       "* **bed_fn** (default: None) [str]\n",
       "\n",
       "Path to a BED file containing the annotation of the transcriptome used as reference when mapping.\n",
       "\n",
       "* **outpath** (default: results) [str]\n",
       "\n",
       "Path to the output folder.\n",
       "\n",
       "* **outprefix** (default: out_) [str]\n",
       "\n",
       "text outprefix for all the files generated by the function.\n",
       "\n",
       "* **overwrite** (default: False) [bool]\n",
       "\n",
       "If the output directory already exists, the standard behaviour is to raise an error to prevent overwriting existing data This option ignore the error and overwrite data if they have the same outpath and outprefix.\n",
       "\n",
       "* **whitelist** (default: None) [Whitelist]\n",
       "\n",
       "Whitelist object previously generated with nanocompore Whitelist. If not given, will be automatically generated.\n",
       "\n",
       "* **comparison_methods** (default: ['GMM', 'KS']) [list]\n",
       "\n",
       "Statistical method to compare the 2 samples (mann_whitney or MW, kolmogorov_smirnov or KS, t_test or TT, gaussian_mixture_model or GMM). This can be a list or a comma separated string. {MW,KS,TT,GMM}\n",
       "\n",
       "* **logit** (default: False) [bool]\n",
       "\n",
       "Force logistic regression even if we have less than 2 replicates in any condition.\n",
       "\n",
       "* **allow_warnings** (default: False) [bool]\n",
       "\n",
       "If True runtime warnings during the ANOVA tests don't raise an error.\n",
       "\n",
       "* **sequence_context** (default: 0) [int]\n",
       "\n",
       "Extend statistical analysis to contigous adjacent base if available.\n",
       "\n",
       "* **sequence_context_weights** (default: uniform) [str]\n",
       "\n",
       "type of weights to used for combining p-values. {uniform,harmonic}\n",
       "\n",
       "* **min_coverage** (default: 30) [int]\n",
       "\n",
       "minimal read coverage required in all sample.\n",
       "\n",
       "* **min_ref_length** (default: 100) [int]\n",
       "\n",
       "minimal length of a reference transcript to be considered in the analysis\n",
       "\n",
       "* **downsample_high_coverage** (default: 0) [int]\n",
       "\n",
       "For reference with higher coverage, downsample by randomly selecting reads.\n",
       "\n",
       "* **max_invalid_kmers_freq** (default: 0.1) [float]\n",
       "\n",
       "maximum frequency of NNNNN, mismatching and missing kmers in reads.\n",
       "\n",
       "* **select_ref_id** (default: []) [list]\n",
       "\n",
       "if given, only reference ids in the list will be selected for the analysis.\n",
       "\n",
       "* **exclude_ref_id** (default: []) [list]\n",
       "\n",
       "if given, refid in the list will be excluded from the analysis.\n",
       "\n",
       "* **nthreads** (default: 3) [int]\n",
       "\n",
       "Number of threads (two are used for reading and writing, all the others for parallel processing).\n",
       "\n",
       "* **log_level** (default: info) [str]\n",
       "\n",
       "Set the log level. {warning,info,debug}\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nanocompore.SampComp import SampComp\n",
    "from nanocompore.common import jhelp\n",
    "jhelp(SampComp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLI documentation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T11:45:31.904837Z",
     "start_time": "2019-04-03T11:45:31.878004Z"
    }
   },
   "source": [
    "```bash\n",
    "nanocompore sampcomp --help\n",
    "```\n",
    "\n",
    "```text\n",
    "usage: nanocompore sampcomp [-h] [--sample_yaml sample_yaml]\n",
    "                            [--file_list1 /path/to/Condition1_rep1,/path/to/Condition1_rep2]\n",
    "                            [--file_list2 /path/to/Condition2_rep1,/path/to/Condition2_rep2]\n",
    "                            [--label1 Condition1] [--label2 Condition2]\n",
    "                            --fasta FASTA [--bed BED] [--outpath OUTPATH]\n",
    "                            [--outprefix OUTPREFIX] [--overwrite]\n",
    "                            [--max_invalid_kmers_freq MAX_INVALID_KMERS_FREQ]\n",
    "                            [--min_coverage MIN_COVERAGE]\n",
    "                            [--downsample_high_coverage DOWNSAMPLE_HIGH_COVERAGE]\n",
    "                            [--min_ref_length MIN_REF_LENGTH]\n",
    "                            [--comparison_methods COMPARISON_METHODS]\n",
    "                            [--sequence_context {0,1,2,3,4}]\n",
    "                            [--sequence_context_weights {uniform,harmonic}]\n",
    "                            [--pvalue_thr PVALUE_THR] [--logit]\n",
    "                            [--allow_warnings] [--nthreads NTHREADS]\n",
    "                            [--log_level {warning,info,debug}]\n",
    "\n",
    "Compare 2 samples and find significant signal\n",
    "\n",
    "* Minimal example with file_list arguments\n",
    "\n",
    "    nanocompore sampcomp -1 f1.tsv,f2.tsv -2 f3.tsv,f4.tsv -f ref.fa -o results\n",
    "* Minimal example with sample YAML file\n",
    "\n",
    "    nanocompore sampcomp -y samples.yaml -f ref -o results\n",
    "\n",
    "optional arguments:\n",
    "  -h, --help            show this help message and exit\n",
    "\n",
    "YAML sample files:\n",
    "  Option allowing to describe sample files in a YAML file\n",
    "\n",
    "  --sample_yaml sample_yaml, -y sample_yaml\n",
    "                        YAML file containing the sample file labels. See\n",
    "                        formatting in documentation. (required if --file_list1\n",
    "                        and --file_list2 not given)\n",
    "\n",
    "Arguments sample files:\n",
    "  Option allowing to describe sample files directly as command line arguments\n",
    "\n",
    "  --file_list1 /path/to/Condition1_rep1,/path/to/Condition1_rep2, -1 /path/to/Condition1_rep1,/path/to/Condition1_rep2\n",
    "                        Comma separated list of NanopolishComp files for label\n",
    "                        1. (required if --sample_yaml not given)\n",
    "  --file_list2 /path/to/Condition2_rep1,/path/to/Condition2_rep2, -2 /path/to/Condition2_rep1,/path/to/Condition2_rep2\n",
    "                        Comma separated list of NanopolishComp files for label\n",
    "                        2. (required if --sample_yaml not given)\n",
    "  --label1 Condition1   Label for files in --file_list1 (default: Condition1)\n",
    "  --label2 Condition2   Label for files in --file_list2 (default: Condition2)\n",
    "\n",
    "Input/Output options:\n",
    "  --fasta FASTA, -f FASTA\n",
    "                        Fasta file used for mapping (required)\n",
    "  --bed BED             BED file with annotation of transcriptome used for\n",
    "                        mapping (optional)\n",
    "  --outpath OUTPATH, -o OUTPATH\n",
    "                        Path to the output folder (default: results)\n",
    "  --outprefix OUTPREFIX, -p OUTPREFIX\n",
    "                        text outprefix for all the files generated by the\n",
    "                        function (default: out_)\n",
    "  --overwrite           Use --outpath even if it exists already (default:\n",
    "                        False)\n",
    "\n",
    "Transcript filtering options:\n",
    "  --max_invalid_kmers_freq MAX_INVALID_KMERS_FREQ\n",
    "                        Max fequency of invalid kmers (default: 0.1)\n",
    "  --min_coverage MIN_COVERAGE\n",
    "                        Minimum coverage required in each condition to do the\n",
    "                        comparison (default: 30)\n",
    "  --downsample_high_coverage DOWNSAMPLE_HIGH_COVERAGE\n",
    "                        Used for debug: transcripts with high covergage will\n",
    "                        be downsampled (default: 0)\n",
    "  --min_ref_length MIN_REF_LENGTH\n",
    "                        Minimum length of a reference transcript to include it\n",
    "                        in the analysis (default: 100)\n",
    "\n",
    "Statistical testing options:\n",
    "  --comparison_methods COMPARISON_METHODS\n",
    "                        Comma separated list of comparison methods. Valid\n",
    "                        methods are: GMM,KS,TT,MW. (default: GMM,KS)\n",
    "  --sequence_context {0,1,2,3,4}\n",
    "                        Sequence context for combining p-values (default: 0)\n",
    "  --sequence_context_weights {uniform,harmonic}\n",
    "                        Type of weights to use for combining p-values\n",
    "  --pvalue_thr PVALUE_THR\n",
    "                        Adjusted p-value threshold for reporting significant\n",
    "                        sites (default: 0.05)\n",
    "  --logit               Use logistic regression testing also when all\n",
    "                        conditions have replicates (default: False)\n",
    "  --allow_warnings      If True runtime warnings during the ANOVA tests don't\n",
    "                        raise an error (default: False)\n",
    "\n",
    "Other options:\n",
    "  --nthreads NTHREADS, -t NTHREADS\n",
    "                        Number of threads (default: 3)\n",
    "  --log_level {warning,info,debug}\n",
    "                        log level (default: info)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "hide_input": false,
  "kernelspec": {
   "display_name": "nanocompore",
   "language": "python",
   "name": "nanocompore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
